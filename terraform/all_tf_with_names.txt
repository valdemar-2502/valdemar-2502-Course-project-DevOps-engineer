=== ./security-groups.tf ===
# Bastion Security Group
resource "yandex_vpc_security_group" "bastion_sg" {
  name        = "bastion-security-group"
  description = "Security group for bastion host"  
  network_id  = yandex_vpc_network.main.id

  ingress {
    description    = "SSH from anywhere"
    protocol       = "TCP"
    port           = 22
    v4_cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    description    = "Allow all outgoing traffic"
    protocol       = "ANY"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

# Web Servers Security Group
resource "yandex_vpc_security_group" "web_sg" {
  name        = "web-security-group"
  description = "Security group for web servers"
  network_id  = yandex_vpc_network.main.id

  ingress {
    description    = "HTTP from Load Balancer"
    protocol       = "TCP"
    port           = 80
    v4_cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    description    = "Node Exporter from Prometheus"
    protocol       = "TCP"
    port           = 9100
    security_group_id = yandex_vpc_security_group.prometheus_sg.id
  }

  ingress {
    description    = "Nginx Log Exporter from Prometheus"
    protocol       = "TCP"
    port           = 4040
    security_group_id = yandex_vpc_security_group.prometheus_sg.id
  }

  ingress {
    description    = "SSH from Bastion"
    protocol       = "TCP"
    port           = 22
    security_group_id = yandex_vpc_security_group.bastion_sg.id
  }

  # УДАЛИТЕ этот ingress - web серверы НЕ должны принимать входящие подключения на 9200
  # Вместо этого добавьте egress для исходящих подключений
  # ingress {
  #   description    = "Filebeat to Elasticsearch"
  #   protocol       = "TCP"
  #   port           = 9200
  #   security_group_id = yandex_vpc_security_group.elasticsearch_sg.id
  # }

  egress {
    description    = "Filebeat to Elasticsearch"
    protocol       = "TCP"
    port           = 9200
    v4_cidr_blocks = [var.private_subnet_cidr_a]
  }

  egress {
    description    = "Allow all outgoing traffic"
    protocol       = "ANY"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

# Prometheus Security Group
resource "yandex_vpc_security_group" "prometheus_sg" {
  name        = "prometheus-security-group"
  description = "Security group for Prometheus"
  network_id  = yandex_vpc_network.main.id

  ingress {
    description    = "Prometheus UI from Grafana"
    protocol       = "TCP"
    port           = 9090
    security_group_id = yandex_vpc_security_group.grafana_sg.id
  }

  ingress {
    description    = "SSH from Bastion"
    protocol       = "TCP"
    port           = 22
    security_group_id = yandex_vpc_security_group.bastion_sg.id
  }

  egress {
    description    = "Allow all outgoing traffic"
    protocol       = "ANY"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

# Grafana Security Group
resource "yandex_vpc_security_group" "grafana_sg" {
  name        = "grafana-security-group"
  description = "Security group for Grafana"
  network_id  = yandex_vpc_network.main.id

  ingress {
    description    = "Grafana UI from anywhere"
    protocol       = "TCP"
    port           = 3000
    v4_cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    description    = "SSH from Bastion"
    protocol       = "TCP"
    port           = 22
    security_group_id = yandex_vpc_security_group.bastion_sg.id
  }

  egress {
    description    = "Allow all outgoing traffic"
    protocol       = "ANY"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

# Elasticsearch Security Group
resource "yandex_vpc_security_group" "elasticsearch_sg" {
  name        = "elasticsearch-security-group"
  description = "Security group for Elasticsearch"
  network_id  = yandex_vpc_network.main.id

  ingress {
    description    = "Elasticsearch API from Kibana"
    protocol       = "TCP"
    port           = 9200
    security_group_id = yandex_vpc_security_group.kibana_sg.id
  }

  # ИЗМЕНИТЕ: вместо security_group_id используйте v4_cidr_blocks
  ingress {
    description    = "Filebeat from Web Servers"
    protocol       = "TCP"
    port           = 9200
    v4_cidr_blocks = [var.private_subnet_cidr_a, var.private_subnet_cidr_b]
  }

  ingress {
    description    = "SSH from Bastion"
    protocol       = "TCP"
    port           = 22
    security_group_id = yandex_vpc_security_group.bastion_sg.id
  }

  egress {
    description    = "Allow all outgoing traffic"
    protocol       = "ANY"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

# Kibana Security Group
resource "yandex_vpc_security_group" "kibana_sg" {
  name        = "kibana-security-group"
  description = "Security group for Kibana"
  network_id  = yandex_vpc_network.main.id

  ingress {
    description    = "Kibana UI from anywhere"
    protocol       = "TCP"
    port           = 5601
    v4_cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    description    = "SSH from Bastion"
    protocol       = "TCP"
    port           = 22
    security_group_id = yandex_vpc_security_group.bastion_sg.id
  }

  egress {
    description    = "Allow all outgoing traffic"
    protocol       = "ANY"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}

# Load Balancer Security Group
resource "yandex_vpc_security_group" "lb_sg" {
  name        = "load-balancer-security-group"
  description = "Security group for Load Balancer"
  network_id  = yandex_vpc_network.main.id

  ingress {
    description    = "HTTP from anywhere"
    protocol       = "TCP"
    port           = 80
    v4_cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    description    = "Allow all outgoing traffic"
    protocol       = "ANY"
    v4_cidr_blocks = ["0.0.0.0/0"]
  }
}
=== ./lb.tf ===
# Target Group for web servers
resource "yandex_lb_target_group" "web" {
  name = "web-target-group"

  target {
    subnet_id  = yandex_vpc_subnet.private_a.id
    address    = yandex_compute_instance.web_1.network_interface.0.ip_address
  }

  target {
    subnet_id  = yandex_vpc_subnet.private_b.id
    address    = yandex_compute_instance.web_2.network_interface.0.ip_address
  }
}

# Network Load Balancer
resource "yandex_lb_network_load_balancer" "web_nlb" {
  name = "web-network-load-balancer"
  type = "external"

  listener {
    name = "web-listener"
    port = 80
    external_address_spec {
      ip_version = "ipv4"
    }
  }

  attached_target_group {
    target_group_id = yandex_lb_target_group.web.id

    healthcheck {
      name                = "http"
      interval            = 2
      timeout             = 1
      unhealthy_threshold = 2
      healthy_threshold   = 2

      http_options {
        port = 80
        path = "/"
      }
    }
  }
}
=== ./outputs.tf ===
output "bastion_public_ip" {
  value       = yandex_compute_instance.bastion.network_interface[0].nat_ip_address
  description = "Public IP address of bastion host"
}

output "load_balancer_ip" {
  value = one([
    for spec in one(yandex_lb_network_load_balancer.web_nlb.listener).external_address_spec : spec.address
  ])
  description = "Public IP address of Network Load Balancer"
}

output "grafana_public_ip" {
  value       = yandex_compute_instance.grafana.network_interface[0].nat_ip_address
  description = "Public IP address of Grafana"
}

output "kibana_public_ip" {
  value       = yandex_compute_instance.kibana.network_interface[0].nat_ip_address
  description = "Public IP address of Kibana"
}

output "web_servers_private_ips" {
  value = {
    web_1 = yandex_compute_instance.web_1.network_interface[0].ip_address
    web_2 = yandex_compute_instance.web_2.network_interface[0].ip_address
  }
  description = "Private IP addresses of web servers"
}

output "prometheus_private_ip" {
  value       = yandex_compute_instance.prometheus.network_interface[0].ip_address
  description = "Private IP address of Prometheus"
}

output "elasticsearch_private_ip" {
  value       = yandex_compute_instance.elasticsearch.network_interface[0].ip_address
  description = "Private IP address of Elasticsearch"
}
=== ./variables.tf ===
variable "yc_token" {
  type      = string
  sensitive = true
  description = "Yandex Cloud OAuth token"
}

variable "yc_cloud_id" {
  type        = string
  description = "Yandex Cloud ID"
}

variable "yc_folder_id" {
  type        = string
  description = "Yandex Cloud folder ID"
}

variable "ssh_public_key_path" {
  type        = string
  default     = "~/.ssh/id_rsa.pub"
  description = "Path to SSH public key"
}

variable "ubuntu_image_id" {
  type        = string
  default     = "fd804teg9bthv0h96s8v"
  description = "Ubuntu 22.04 LTS image ID"
}

# Network variables
variable "vpc_cidr" {
  type        = string
  default     = "10.0.0.0/16"
  description = "VPC CIDR block"
}

variable "public_subnet_cidr" {
  type        = string
  default     = "10.0.1.0/24"
  description = "Public subnet CIDR"
}

variable "private_subnet_cidr_a" {
  type        = string
  default     = "10.0.2.0/24"
  description = "Private subnet A CIDR"
}

variable "private_subnet_cidr_b" {
  type        = string
  default     = "10.0.3.0/24"
  description = "Private subnet B CIDR"
}

# Instance names
variable "bastion_name" {
  type        = string
  default     = "bastion"
  description = "Bastion host name"
}

variable "webserver_names" {
  type        = list(string)
  default     = ["web-1", "web-2"]
  description = "Web server names"
}

variable "prometheus_name" {
  type        = string
  default     = "prometheus"
  description = "Prometheus server name"
}

variable "grafana_name" {
  type        = string
  default     = "grafana"
  description = "Grafana server name"
}

variable "elasticsearch_name" {
  type        = string
  default     = "elasticsearch"
  description = "Elasticsearch server name"
}

variable "kibana_name" {
  type        = string
  default     = "kibana"
  description = "Kibana server name"
}

# Instance types
variable "bastion_instance_type" {
  type        = string
  default     = "standard-v2"
  description = "Bastion instance type"
}

variable "web_instance_type" {
  type        = string
  default     = "standard-v2"
  description = "Web server instance type"
}

variable "prometheus_instance_type" {
  type        = string
  default     = "standard-v2"
  description = "Prometheus instance type"
}

variable "grafana_instance_type" {
  type        = string
  default     = "standard-v2"
  description = "Grafana instance type"
}

variable "elasticsearch_instance_type" {
  type        = string
  default     = "standard-v2"
  description = "Elasticsearch instance type"
}

variable "kibana_instance_type" {
  type        = string
  default     = "standard-v2"
  description = "Kibana instance type"
}
=== ./vpc.tf ===
# VPC
resource "yandex_vpc_network" "main" {
  name = "infra-project-vpc"
}

# Public subnet
resource "yandex_vpc_subnet" "public" {
  name           = "public-subnet"
  zone           = "ru-central1-a"
  network_id     = yandex_vpc_network.main.id
  v4_cidr_blocks = [var.public_subnet_cidr]
}

# Private subnet A
resource "yandex_vpc_subnet" "private_a" {
  name           = "private-subnet-a"
  zone           = "ru-central1-a"
  network_id     = yandex_vpc_network.main.id
  v4_cidr_blocks = [var.private_subnet_cidr_a]
  route_table_id = yandex_vpc_route_table.nat.id
}

# Private subnet B
resource "yandex_vpc_subnet" "private_b" {
  name           = "private-subnet-b"
  zone           = "ru-central1-b"
  network_id     = yandex_vpc_network.main.id
  v4_cidr_blocks = [var.private_subnet_cidr_b]
  route_table_id = yandex_vpc_route_table.nat.id
}

# NAT Gateway
resource "yandex_vpc_gateway" "nat_gateway" {
  name = "nat-gateway"
  shared_egress_gateway {}
}

# Route table for NAT
resource "yandex_vpc_route_table" "nat" {
  name       = "nat-route-table"
  network_id = yandex_vpc_network.main.id

  static_route {
    destination_prefix = "0.0.0.0/0"
    gateway_id         = yandex_vpc_gateway.nat_gateway.id
  }
}
=== ./main.tf ===
terraform {
  required_version = ">= 1.0"
  required_providers {
    yandex = {
      source  = "yandex-cloud/yandex"
      version = ">= 0.89"
    }
  }
}

provider "yandex" {
  token     = var.yc_token
  cloud_id  = var.yc_cloud_id
  folder_id = var.yc_folder_id
  zone      = "ru-central1-a"
}
=== ./compute.tf ===
# Bastion Host
resource "yandex_compute_instance" "bastion" {
  name        = var.bastion_name
  platform_id = var.bastion_instance_type
  zone        = "ru-central1-a"
  hostname    = var.bastion_name

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = var.ubuntu_image_id
      size     = 10
    }
  }

  network_interface {
    subnet_id = yandex_vpc_subnet.public.id
    nat       = true
    security_group_ids = [yandex_vpc_security_group.bastion_sg.id]
  }

  metadata = {
    ssh-keys = "ubuntu:${file(var.ssh_public_key_path)}"
    user-data = <<-EOF
      #cloud-config
      write_files:
        - path: /etc/sysctl.d/10-ip-forward.conf
          content: |
            net.ipv4.ip_forward=1
            net.ipv6.conf.all.forwarding=1
      runcmd:
        - sysctl -p /etc/sysctl.d/10-ip-forward.conf
        - iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
        - iptables -A FORWARD -i eth0 -o eth0 -j ACCEPT
        - apt-get update
        - apt-get install -y iptables-persistent
        - netfilter-persistent save
      EOF
  }
}

# Web Server 1
resource "yandex_compute_instance" "web_1" {
  name        = var.webserver_names[0]
  platform_id = var.web_instance_type
  zone        = "ru-central1-a"
  hostname    = var.webserver_names[0]

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = var.ubuntu_image_id
      size     = 10
    }
  }

  network_interface {
    subnet_id = yandex_vpc_subnet.private_a.id
    nat       = false
    security_group_ids = [yandex_vpc_security_group.web_sg.id]
  }

  metadata = {
    ssh-keys = "ubuntu:${file(var.ssh_public_key_path)}"
  }
}

# Web Server 2
resource "yandex_compute_instance" "web_2" {
  name        = var.webserver_names[1]
  platform_id = var.web_instance_type
  zone        = "ru-central1-b"
  hostname    = var.webserver_names[1]

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = var.ubuntu_image_id
      size     = 10
    }
  }

  network_interface {
    subnet_id = yandex_vpc_subnet.private_b.id
    nat       = false
    security_group_ids = [yandex_vpc_security_group.web_sg.id]
  }

  metadata = {
    ssh-keys = "ubuntu:${file(var.ssh_public_key_path)}"
  }
}

# Prometheus Server
resource "yandex_compute_instance" "prometheus" {
  name        = var.prometheus_name
  platform_id = var.prometheus_instance_type
  zone        = "ru-central1-a"
  hostname    = var.prometheus_name

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = var.ubuntu_image_id
      size     = 10
    }
  }

  network_interface {
    subnet_id = yandex_vpc_subnet.private_a.id
    nat       = false
    security_group_ids = [yandex_vpc_security_group.prometheus_sg.id]
  }

  metadata = {
    ssh-keys = "ubuntu:${file(var.ssh_public_key_path)}"
  }
}

# Grafana Server
resource "yandex_compute_instance" "grafana" {
  name        = var.grafana_name
  platform_id = var.grafana_instance_type
  zone        = "ru-central1-a"
  hostname    = var.grafana_name

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = var.ubuntu_image_id
      size     = 10
    }
  }

  network_interface {
    subnet_id = yandex_vpc_subnet.public.id
    nat       = true
    security_group_ids = [yandex_vpc_security_group.grafana_sg.id]
  }

  metadata = {
    ssh-keys = "ubuntu:${file(var.ssh_public_key_path)}"
  }
}

# Elasticsearch Server
resource "yandex_compute_instance" "elasticsearch" {
  name        = var.elasticsearch_name
  platform_id = var.elasticsearch_instance_type
  zone        = "ru-central1-a"
  hostname    = var.elasticsearch_name

  resources {
    cores  = 4
    memory = 8
  }

  boot_disk {
    initialize_params {
      image_id = var.ubuntu_image_id
      size     = 30
    }
  }

  network_interface {
    subnet_id = yandex_vpc_subnet.private_a.id
    nat       = false
    security_group_ids = [yandex_vpc_security_group.elasticsearch_sg.id]
  }

  metadata = {
    ssh-keys = "ubuntu:${file(var.ssh_public_key_path)}"
  }
}

# Kibana Server
resource "yandex_compute_instance" "kibana" {
  name        = var.kibana_name
  platform_id = var.kibana_instance_type
  zone        = "ru-central1-a"
  hostname    = var.kibana_name

  resources {
    cores  = 2
    memory = 2
  }

  boot_disk {
    initialize_params {
      image_id = var.ubuntu_image_id
      size     = 10
    }
  }

  network_interface {
    subnet_id = yandex_vpc_subnet.public.id
    nat       = true
    security_group_ids = [yandex_vpc_security_group.kibana_sg.id]
  }

  metadata = {
    ssh-keys = "ubuntu:${file(var.ssh_public_key_path)}"
  }
}
=== ./backup.tf ===
# Snapshot schedule for all instances
resource "yandex_compute_snapshot_schedule" "daily_backup" {
  name = "daily-backup-schedule"

  schedule_policy {
    expression = "0 2 * * *" # Daily at 02:00
  }

  retention_period = "168h" # 7 days in hours

  snapshot_count = 7 # Keep 7 snapshots

  snapshot_spec {
    description = "Daily backup"
  }

  # Attach all instance disks
  disk_ids = [
    yandex_compute_instance.bastion.boot_disk[0].disk_id,
    yandex_compute_instance.web_1.boot_disk[0].disk_id,
    yandex_compute_instance.web_2.boot_disk[0].disk_id,
    yandex_compute_instance.prometheus.boot_disk[0].disk_id,
    yandex_compute_instance.grafana.boot_disk[0].disk_id,
    yandex_compute_instance.elasticsearch.boot_disk[0].disk_id,
    yandex_compute_instance.kibana.boot_disk[0].disk_id,
  ]
}
